import React, { useMemo, useState, useEffect, useRef, useCallback } from 'react'
import { UIMessage, useChat } from '@ai-sdk/react'
import { DefaultChatTransport, lastAssistantMessageIsCompleteWithToolCalls } from 'ai'
import { nanoid } from 'nanoid'
import { ActionIcon, Badge, Box, Button, CopyButton, Divider, Group, Loader, Modal, Paper, ScrollArea, Select, Stack, Text, Textarea, Tooltip } from '@mantine/core'
import { IconX, IconSparkles, IconSend, IconPhoto, IconBulb, IconEye, IconWifi, IconBattery2, IconDots, IconMicrophone, IconMoodSmile } from '@tabler/icons-react'
import { getDefaultModel, getModelProvider, type ModelOption } from '../../config/models'
import { useModelOptions } from '../../config/useModelOptions'
import { useRFStore } from '../store'
import { getAuthToken } from '../../auth/store'
import { functionHandlers } from '../../ai/canvasService'
import { subscribeToolEvents, type ToolEventMessage, extractThinkingEvent, extractPlanUpdate } from '../../api/toolEvents'
import { runTaskByVendor, type TaskResultDto, listModelProviders, listModelTokens } from '../../api/server'
import { toast } from '../../ui/toast'
import { DEFAULT_REVERSE_PROMPT_INSTRUCTION } from '../constants'
import type { ThinkingEvent, PlanUpdatePayload } from '../../types/canvas-intelligence'
import { buildCanvasContext } from '../utils/buildCanvasContext'

type AssistantPosition = 'right' | 'left'

interface UseChatAssistantProps {
  opened: boolean
  onClose: () => void
  position?: AssistantPosition
  width?: number
  intelligentMode?: boolean
}

const OPENAI_DEFAULT_MODEL = 'gpt-5.1-codex'
const ASSISTANT_MODEL_PRESETS: ModelOption[] = [
  { value: 'gpt-5.1', label: 'GPT-5.1' },
  { value: 'gpt-5.1-codex', label: 'GPT-5.1 Codex' },
]
const ASSISTANT_MODEL_SET = new Set(ASSISTANT_MODEL_PRESETS.map(option => option.value))
const MAX_IMAGE_PROMPT_ATTACHMENTS = 2
const AI_DEBUG_LOGS_ENABLED = (import.meta as any).env?.VITE_DEBUG_AI_LOGS === 'true'

const buildAssistantBaseOptions = (textOptions: ModelOption[]): ModelOption[] => {
  const overrides = new Map<string, ModelOption>()
  textOptions.forEach((option) => {
    if (ASSISTANT_MODEL_SET.has(option.value)) {
      overrides.set(option.value, option)
    }
  })
  return ASSISTANT_MODEL_PRESETS.map((option) => overrides.get(option.value) || option)
}

const filterGptOptions = (options: ModelOption[]): ModelOption[] =>
  options.filter((option) => option.value.toLowerCase().includes('gpt'))

const mergeModelOptionLists = (primary: ModelOption[], extra: ModelOption[]): ModelOption[] => {
  const seen = new Set<string>()
  const merged: ModelOption[] = []
  primary.forEach((opt) => {
    if (seen.has(opt.value)) return
    seen.add(opt.value)
    merged.push(opt)
  })
  extra.forEach((opt) => {
    if (seen.has(opt.value)) return
    seen.add(opt.value)
    merged.push(opt)
  })
  return merged
}

async function fetchAssistantCodexModels(): Promise<ModelOption[]> {
  try {
    const providers = await listModelProviders().catch(() => [])
    const openaiProvider = providers.find((provider) => provider.vendor === 'openai')
    if (!openaiProvider) return []
    const baseUrl = (openaiProvider.baseUrl || '').trim()
    if (!baseUrl) return []
    const tokens = await listModelTokens(openaiProvider.id).catch(() => [])
    const token = tokens.find((t) => t.enabled && typeof t.secretToken === 'string' && t.secretToken.trim())
    if (!token?.secretToken) return []
    const normalizedBase = baseUrl.replace(/\/$/, '')
    const endpoint = `${normalizedBase}/v1/models`
    console.debug('[UseChatAssistant] è¯·æ±‚ GPT æ¨¡å‹åˆ—è¡¨', {
      baseUrl: normalizedBase,
      endpoint,
      tokenLabel: token.label || 'æœªå‘½åå¯†é’¥',
    })
    const resp = await fetch(endpoint, {
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${token.secretToken}`,
      },
    })
    if (!resp.ok) {
      console.warn('[UseChatAssistant] Codex model fetch failed', resp.status)
      return []
    }
    let payload: any = null
    try {
      payload = await resp.json()
    } catch {
      payload = null
    }
    console.debug('[UseChatAssistant] GPT æ¨¡å‹å“åº”', payload)
    const list = Array.isArray(payload?.data)
      ? payload.data
      : Array.isArray(payload?.models)
        ? payload.models
        : Array.isArray(payload)
          ? payload
          : []
    return list
      .map((item) => {
        const value = typeof item?.id === 'string' ? item.id : typeof item?.name === 'string' ? item.name : null
        if (!value) return null
        if (!value.toLowerCase().includes('gpt')) return null
        const label = typeof item?.displayName === 'string' && item.displayName.trim() ? item.displayName.trim() : value
        return { value, label, vendor: 'openai' as const }
      })
      .filter(Boolean) as ModelOption[]
  } catch (error) {
    console.warn('[UseChatAssistant] failed to load Codex models', error)
    return []
  }
}

const collectTextFromParts = (parts?: any): string => {
  if (!Array.isArray(parts)) return ''
  const buffer: string[] = []
  const pushPart = (part: any) => {
    if (!part) return
    if (typeof part === 'string' && part.trim()) {
      buffer.push(part.trim())
      return
    }
    const candidates: (string | undefined)[] = [
      typeof part.text === 'string' ? part.text : undefined,
      typeof part.content === 'string' ? part.content : undefined,
      typeof part.output_text === 'string' ? part.output_text : undefined,
      typeof part.value === 'string' ? part.value : undefined,
    ]
    candidates.forEach((text) => {
      if (text && text.trim()) {
        buffer.push(text.trim())
      }
    })
    if (Array.isArray(part.content)) {
      part.content.forEach(pushPart)
    }
  }
  parts.forEach(pushPart)
  return buffer.join('').trim()
}

const extractTextFromResponsePayload = (payload: any): string => {
  if (!payload || typeof payload !== 'object') return ''

  if (typeof payload.text === 'string' && payload.text.trim()) {
    return payload.text.trim()
  }

  if (Array.isArray(payload.output_text)) {
    const merged = payload.output_text
      .map((entry: any) => (typeof entry === 'string' ? entry : ''))
      .join('')
      .trim()
    if (merged) return merged
  }

  if (Array.isArray(payload.output)) {
    const merged = payload.output
      .map((entry: any) => collectTextFromParts(entry?.content))
      .filter(Boolean)
      .join('\n')
      .trim()
    if (merged) return merged
  }

  if (Array.isArray(payload.content)) {
    const merged = collectTextFromParts(payload.content)
    if (merged) return merged
  }

  const choices = payload.choices
  if (Array.isArray(choices) && choices.length > 0) {
    const message = choices[0]?.message
    const choiceText =
      (typeof message?.content === 'string' && message.content.trim()) ||
      collectTextFromParts(message?.content) ||
      (typeof choices[0]?.text === 'string' ? choices[0].text.trim() : '')
    if (choiceText) return choiceText
  }

  const candidates = payload.candidates
  if (Array.isArray(candidates) && candidates.length > 0) {
    const merged = collectTextFromParts(candidates[0]?.content?.parts || candidates[0]?.content)
    if (merged) return merged
  }

  if (payload.result) {
    const nested = extractTextFromResponsePayload(payload.result)
    if (nested) return nested
  }

  return ''
}

const toSingleLine = (text?: string) => (typeof text === 'string' ? text.replace(/\s+/g, ' ').trim() : '')

const extractTextFromTaskResult = (task?: TaskResultDto | null): string => {
  if (!task) return ''
  const raw = task.raw as any
  if (raw && typeof raw.text === 'string' && raw.text.trim()) {
    return raw.text.trim()
  }
  const fromResponse = extractTextFromResponsePayload(raw?.response || raw)
  if (fromResponse) return fromResponse
  return ''
}

const fileToDataUrl = (file: File) =>
  new Promise<string>((resolve, reject) => {
    const reader = new FileReader()
    reader.onloadend = () => {
      const result = reader.result
      if (typeof result === 'string') resolve(result)
      else reject(new Error('failed to read file'))
    }
    reader.onerror = () => reject(new Error('failed to read file'))
    reader.readAsDataURL(file)
  })

interface ImagePromptAttachment {
  id: string
  preview: string
  prompt: string
  ready: boolean
}

const normalizeFileList = (files: FileList | File[]): File[] => {
  if (Array.isArray(files)) {
    return files.filter((file): file is File => !!file)
  }
  const out: File[] = []
  for (let i = 0; i < files.length; i += 1) {
    const item = files.item(i)
    if (item) out.push(item)
  }
  return out
}

/**
 * æš—å¤œAIåŠ©æ‰‹ï¼ˆæµå¼ç‰ˆï¼‰ï¼ŒåŸºäº @ai-sdk/react çš„ useChatã€‚
 * åŒ¹é…åŸ SimpleAIAssistant çš„å¼¹çª—è¡Œä¸ºï¼Œä½¿ç”¨åç«¯ /ai/chat SSEã€‚
 */
export function UseChatAssistant({ opened, onClose, position = 'right', width = 420, intelligentMode = true }: UseChatAssistantProps) {
  const nodes = useRFStore(state => state.nodes)
  const edges = useRFStore(state => state.edges)
  const [model, setModel] = useState(() => OPENAI_DEFAULT_MODEL || getDefaultModel('text'))
  const textModelOptions = useModelOptions('text')
  const [codexModels, setCodexModels] = useState<ModelOption[]>([])
  const fallbackAssistantOptions = useMemo(() => buildAssistantBaseOptions(textModelOptions), [textModelOptions])
  const gptTextOptions = useMemo(() => filterGptOptions(textModelOptions), [textModelOptions])
  const assistantModelOptions = useMemo(() => {
    const primary = gptTextOptions.length ? gptTextOptions : fallbackAssistantOptions
    return mergeModelOptionLists(primary, codexModels)
  }, [gptTextOptions, fallbackAssistantOptions, codexModels])
  const apiBase = (import.meta as any).env?.VITE_API_BASE || 'http://localhost:3000'
  const apiRoot = useMemo(() => apiBase.replace(/\/$/, ''), [apiBase])
  const panelBackground = 'radial-gradient(135% 160% at 50% 0%, rgba(36,52,104,0.45), rgba(5,7,15,0.98))'
  const panelBorder = 'none'
  const panelShadow = '0 45px 120px rgba(3,5,15,0.85)'
  const headerBackground = 'rgba(5,8,20,0.55)'
  const headerBorder = 'none'
  const sparklesColor = '#a5b4fc'
  const logBackground = 'radial-gradient(80% 60% at 50% 0%, rgba(79,126,255,0.22), transparent), rgba(4,7,16,0.9)'
  const logBorder = 'none'
  const messageTextColor = '#f4f7ff'
  const inputBackground = 'rgba(8,12,24,0.9)'
  const inputBorder = 'none'
  const inputColor = '#f8fbff'
  const closeIconColor = '#d1d9ff'
  const userBubbleBackground = 'linear-gradient(135deg, rgba(61,123,255,0.95), rgba(101,232,255,0.95))'
  const userBubbleBorder = '1px solid rgba(255,255,255,0.18)'
  const assistantBubbleBackground = 'rgba(255,255,255,0.05)'
  const assistantBubbleBorder = '1px solid rgba(255,255,255,0.05)'
  const bubbleShadow = '0 24px 60px rgba(3,5,15,0.65)'
  const toolbarIconBackground = 'rgba(255,255,255,0.05)'
  const toolbarIconBorder = '1px solid rgba(255,255,255,0.08)'
  const glowingSendBackground = 'linear-gradient(135deg, #3d7eff, #6ae0ff)'
  const imagePromptInputRef = useRef<HTMLInputElement | null>(null)
  const scrollAreaViewportRef = useRef<HTMLDivElement | null>(null)
  const [imagePromptLoadingCount, setImagePromptLoadingCount] = useState(0)
  const imagePromptLoading = imagePromptLoadingCount > 0
  const [imagePromptAttachments, setImagePromptAttachments] = useState<ImagePromptAttachment[]>([])
  const [activePromptAttachmentId, setActivePromptAttachmentId] = useState<string | null>(null)
  const activePromptAttachment = useMemo(
    () => imagePromptAttachments.find(attachment => attachment.id === activePromptAttachmentId) || null,
    [imagePromptAttachments, activePromptAttachmentId]
  )
  const [thinkingEvents, setThinkingEvents] = useState<ThinkingEvent[]>([])
  const [planUpdate, setPlanUpdate] = useState<PlanUpdatePayload | null>(null)
  const [isThinking, setIsThinking] = useState(false)

  useEffect(() => {
    if (!opened) return
    let canceled = false
    fetchAssistantCodexModels()
      .then((models) => {
        if (canceled) return
        setCodexModels(models)
      })
      .catch(() => {})
    return () => {
      canceled = true
    }
  }, [opened])

  useEffect(() => {
    if (assistantModelOptions.length && !assistantModelOptions.find(option => option.value === model)) {
      const preferred = assistantModelOptions.find(option => option.value === OPENAI_DEFAULT_MODEL)
      setModel(preferred ? preferred.value : assistantModelOptions[0].value)
    }
  }, [assistantModelOptions, model])

  const canvasContext = useMemo(() => buildCanvasContext(nodes, edges), [nodes, edges])

  const provider = useMemo(() => {
    const match = assistantModelOptions.find((opt) => opt.value === model)
    if (match?.vendor) {
      if (match.vendor === 'gemini') return 'google'
      if (['openai', 'anthropic', 'google'].includes(match.vendor)) {
        return match.vendor as ReturnType<typeof getModelProvider>
      }
    }
    return getModelProvider(model)
  }, [model, assistantModelOptions])
  const isGptModel = provider === 'openai'

  const body = useMemo(() => ({
    model,
    context: canvasContext,
    provider,
    clientToolExecution: true, // å§‹ç»ˆè®©å‰ç«¯æ‰§è¡Œå·¥å…·ï¼Œæ™ºèƒ½æ¨¡å¼ä»ç”±åç«¯ sidecar æä¾›
    maxToolRoundtrips: 4,
    intelligentMode,
    enableThinking: true,
  }), [model, canvasContext, provider, intelligentMode])

  const chatId = useMemo(() => `${model}-${nanoid()}`, [model])

  const chatTransport = useMemo(() => new DefaultChatTransport({
    api: `${apiRoot}/ai/chat/stream`,
    streamProtocol: 'sse',
    prepareSendMessagesRequest: ({ messages }) => {
      const serializedMessages = messages.map(({ id: _id, ...rest }) => ({
        role: rest.role,
        metadata: rest.metadata,
        parts: (rest.parts || []).map(part => {
          if (part.type === 'data') {
            if (typeof part.data === 'string') return part
            try {
              return { ...part, data: JSON.stringify(part.data) }
            } catch {
              return { ...part, data: String(part.data) }
            }
          }
          return part
        })
      }))
      return {
        headers: {
          'Content-Type': 'application/json',
          ...(getAuthToken() ? { Authorization: `Bearer ${getAuthToken()}` } : {})
        },
        body: {
          ...body,
          messages: serializedMessages,
        }
      }
    }
  }), [apiRoot, body, model, intelligentMode])

  const parseJsonIfNeeded = (value: any) => {
    if (typeof value === 'string') {
      try {
        return JSON.parse(value)
      } catch {
        return value
      }
    }
    if (value == null) return {}
    return value
  }

  const { messages, sendMessage, status, setMessages, addToolResult } = useChat({
    id: chatId,
    transport: chatTransport,
    sendAutomaticallyWhen: ({ messages }) => lastAssistantMessageIsCompleteWithToolCalls({ messages })
  })
  const handledToolCalls = useRef(new Set<string>())
  const resolveToolName = (part: any) => {
    if (part?.toolName) return part.toolName
    if (typeof part?.type === 'string' && part.type.startsWith('tool-')) {
      return part.type.slice('tool-'.length)
    }
    return undefined
  }

  const isToolCallPart = (part: any) => {
    if (!part) return false
    const { state } = part
    if (state === 'input-streaming') return false
    if (part.type === 'tool-input-available') return true
    if (part.type === 'tool-call' || part.type === 'dynamic-tool') return true
    if (typeof part.type === 'string') {
      const type = part.type
      if (type === 'tool-result') return false
      if (type.startsWith('tool-input')) return type.endsWith('available')
      if (type.startsWith('tool-')) return true
    }
    return Boolean(part.toolName && part.toolCallId)
  }

  const PROMPT_FIELD_KEYS = new Set(['prompt', 'videoPrompt', 'description', 'story', 'script', 'text'])
  const MAX_SUMMARY_DEPTH = 4
  const truncateText = (value: string, limit = 160) => {
    const normalized = value.replace(/\s+/g, ' ').trim()
    if (!normalized) return ''
    if (normalized.length <= limit) return normalized
    return `${normalized.slice(0, limit - 1)}â€¦`
  }
  const summarizePromptText = (value: string) => {
    const normalized = value.replace(/\s+/g, ' ').trim()
    if (!normalized) return ''
    const limit = 80
    if (normalized.length <= limit) return normalized
    return `${normalized.slice(0, limit)}â€¦ï¼ˆ${normalized.length}å­—ï¼‰`
  }
  const summarizeArrayPreview = (arr: any[], depth: number) => {
    if (!arr.length) return ''
    if (depth > 1) return `[${arr.length} é¡¹]`
    const preview = arr
      .slice(0, 3)
      .map(item => summarizePayload(item, depth + 1))
      .filter(Boolean)
    const suffix = arr.length > 3 ? `â€¦+${arr.length - 3}` : ''
    return `[${preview.join(', ')}${suffix}]`
  }
  const summarizeField = (key: string, value: any, depth: number): string => {
    if (value == null) return ''
    if (PROMPT_FIELD_KEYS.has(key) && typeof value === 'string') {
      const snippet = summarizePromptText(value)
      return snippet ? `${key}=${snippet}` : ''
    }
    if (key === 'nodeIds' && Array.isArray(value)) {
      if (!value.length) return ''
      const preview = value.slice(0, 3).join(', ')
      const suffix = value.length > 3 ? `â€¦+${value.length - 3}` : ''
      return `${key}=${preview}${suffix}`
    }
    if (key === 'position' && typeof value === 'object') {
      const coords: string[] = []
      if (typeof value.x === 'number') coords.push(`x:${Math.round(value.x)}`)
      if (typeof value.y === 'number') coords.push(`y:${Math.round(value.y)}`)
      return coords.length ? `${key}=${coords.join(', ')}` : ''
    }
    const summarized = summarizePayload(value, depth)
    return summarized ? `${key}=${summarized}` : ''
  }
  const summarizeRecord = (record: Record<string, any>, depth: number): string => {
    if (!record || depth > MAX_SUMMARY_DEPTH) return ''
    if (typeof record.success === 'boolean') {
      const state = record.success ? 'æˆåŠŸ' : 'å¤±è´¥'
      const details: string[] = []
      if (record.success && record.data) {
        const dataText = summarizePayload(record.data, depth + 1)
        if (dataText) details.push(dataText)
      }
      if (!record.success) {
        if (record.error) {
          const errorText = summarizePayload(record.error, depth + 1)
          if (errorText) details.push(errorText)
        }
        if (record.data) {
          const fallback = summarizePayload(record.data, depth + 1)
          if (fallback) details.push(fallback)
        }
      }
      return [state, ...details].filter(Boolean).join(' Â· ')
    }
    const message = typeof record.message === 'string' ? truncateText(record.message, 140) : ''
    const prioritizedKeys = ['action', 'type', 'label', 'nodeId', 'nodeIds', 'sourceNodeId', 'targetNodeId', 'sourceHandle', 'targetHandle', 'layoutType', 'status', 'count', 'remixFromNodeId', 'position']
    const used = new Set<string>()
    const fields: string[] = []
    prioritizedKeys.forEach(key => {
      if (!(key in record)) return
      const text = summarizeField(key, record[key], depth + 1)
      if (text) {
        used.add(key)
        fields.push(text)
      }
    })
    const extraEntries = Object.entries(record)
      .filter(([key]) => key !== 'message' && key !== 'success' && key !== 'data' && key !== 'error' && !used.has(key))
      .slice(0, 3)
      .map(([key, value]) => summarizeField(key, value, depth + 1))
      .filter(Boolean)
    const combined = [message, ...fields, ...extraEntries].filter(Boolean)
    return combined.join(' Â· ')
  }
  function summarizePayload(payload: any, depth = 0): string {
    if (payload == null || depth > MAX_SUMMARY_DEPTH) return ''
    if (typeof payload === 'string') return truncateText(payload)
    if (typeof payload === 'number' || typeof payload === 'boolean') return String(payload)
    if (Array.isArray(payload)) return summarizeArrayPreview(payload, depth)
    if (typeof payload === 'object') {
      return summarizeRecord(payload as Record<string, any>, depth + 1)
    }
    return ''
  }

  const NODE_KIND_LABELS: Record<string, string> = {
    text: 'æ–‡æœ¬',
    image: 'å›¾åƒ',
    video: 'è§†é¢‘',
    composevideo: 'è§†é¢‘',
    composeVideo: 'è§†é¢‘',
    storyboard: 'åˆ†é•œ',
    audio: 'éŸ³é¢‘',
    subtitle: 'å­—å¹•',
    character: 'è§’è‰²',
    texttoimage: 'å›¾åƒ',
    imagetext: 'å›¾åƒ',
  }
  const TOOL_LABELS: Record<string, string> = {
    createNode: 'åˆ›å»ºèŠ‚ç‚¹',
    updateNode: 'æ›´æ–°èŠ‚ç‚¹',
    deleteNode: 'åˆ é™¤èŠ‚ç‚¹',
    connectNodes: 'è¿æ¥èŠ‚ç‚¹',
    disconnectNodes: 'æ–­å¼€è¿æ¥',
    autoLayout: 'åº”ç”¨å¸ƒå±€',
    runNode: 'è¿è¡ŒèŠ‚ç‚¹',
    runDag: 'è¿è¡Œå·¥ä½œæµ',
    formatAll: 'æ•´ç†ç”»å¸ƒ',
    getNodes: 'æŸ¥çœ‹èŠ‚ç‚¹',
    findNodes: 'æŸ¥æ‰¾èŠ‚ç‚¹',
    'canvas.node.operation': 'èŠ‚ç‚¹æ“ä½œ',
    'canvas.connection.operation': 'è¿æ¥æ“ä½œ',
    'canvas.layout.apply': 'å¸ƒå±€è°ƒæ•´',
    'canvas.optimization.analyze': 'ç”»å¸ƒä¼˜åŒ–',
    'canvas.view.navigate': 'è§†å›¾å®šä½',
    'project.operation': 'é¡¹ç›®æ“ä½œ',
    'ai.plan.update': 'è®¡åˆ’åŒæ­¥',
    'ai.thinking.process': 'æ¨ç†åˆ†æ',
  }
  const NODE_OPERATION_ACTION_LABELS: Record<string, string> = {
    create: 'åˆ›å»ºèŠ‚ç‚¹',
    update: 'æ›´æ–°èŠ‚ç‚¹',
    delete: 'åˆ é™¤èŠ‚ç‚¹',
    duplicate: 'å¤åˆ¶èŠ‚ç‚¹',
  }
  const CONNECTION_ACTION_LABELS: Record<string, string> = {
    connect: 'è¿æ¥èŠ‚ç‚¹',
    disconnect: 'æ–­å¼€è¿æ¥',
    reconnect: 'è°ƒæ•´è¿æ¥',
  }
  const LAYOUT_LABELS: Record<string, string> = {
    grid: 'å®«æ ¼å¸ƒå±€',
    horizontal: 'æ°´å¹³å¸ƒå±€',
    hierarchical: 'å±‚çº§å¸ƒå±€',
  }
  const describeNodeSelection = (payload: Record<string, any> = {}) => {
    if (Array.isArray(payload.nodeIds) && payload.nodeIds.length) {
      const preview = payload.nodeIds.slice(0, 2).join('ã€')
      const suffix = payload.nodeIds.length > 2 ? `â€¦ç­‰${payload.nodeIds.length}ä¸ª` : ''
      return `èŠ‚ç‚¹ ${preview}${suffix}`
    }
    const label =
      typeof payload.label === 'string' ? payload.label :
      typeof payload.config?.label === 'string' ? payload.config.label :
      typeof payload.config?.title === 'string' ? payload.config.title :
      ''
    const nodeId = typeof payload.nodeId === 'string' ? payload.nodeId : ''
    const kindValue = payload.config?.kind || payload.kind || payload.type
    const kindLabel = typeof kindValue === 'string' ? NODE_KIND_LABELS[kindValue.toLowerCase()] : ''
    const parts: string[] = []
    if (label) parts.push(`ã€Œ${label}ã€`)
    if (!label && nodeId) parts.push(`èŠ‚ç‚¹ ${nodeId}`)
    if (kindLabel) parts.push(kindLabel)
    return parts.join(' Â· ')
  }
  const describeConnection = (payload: Record<string, any> = {}) => {
    if (Array.isArray(payload.connections) && payload.connections.length) {
      return `${payload.connections.length} æ¡è¿æ¥`
    }
    const source =
      typeof payload.sourceNodeId === 'string' ? payload.sourceNodeId :
      typeof payload.source === 'string' ? payload.source :
      ''
    const target =
      typeof payload.targetNodeId === 'string' ? payload.targetNodeId :
      typeof payload.target === 'string' ? payload.target :
      ''
    if (source && target) return `${source} â†’ ${target}`
    return source || target || ''
  }
  const describeLayout = (payload: Record<string, any> = {}) => {
    const layout = typeof payload.layoutType === 'string'
      ? payload.layoutType
      : typeof payload.layout === 'string'
        ? payload.layout
        : ''
    if (!layout) return ''
    const normalized = layout.toLowerCase()
    return LAYOUT_LABELS[normalized] || layout
  }
  const getBaseToolLabel = (toolName: string, payload: Record<string, any>) => {
    if (toolName === 'canvas.node.operation') {
      const action = typeof payload.action === 'string' ? payload.action : ''
      return NODE_OPERATION_ACTION_LABELS[action] || TOOL_LABELS[toolName] || 'ç”»å¸ƒæ“ä½œ'
    }
    if (toolName === 'canvas.connection.operation') {
      const action = typeof payload.action === 'string' ? payload.action : ''
      return CONNECTION_ACTION_LABELS[action] || TOOL_LABELS[toolName] || 'è¿æ¥æ“ä½œ'
    }
    return TOOL_LABELS[toolName] || 'ç”»å¸ƒæ“ä½œ'
  }
  const buildActionLabel = useCallback((toolName?: string, input?: any) => {
    const normalizedTool = typeof toolName === 'string' ? toolName : ''
    const payload = input && typeof input === 'object' ? input : {}
    const baseLabel = getBaseToolLabel(normalizedTool, payload)
    let detail = ''
    if (normalizedTool === 'createNode' || normalizedTool === 'updateNode' || normalizedTool === 'deleteNode' || normalizedTool === 'runNode' || normalizedTool === 'canvas.node.operation') {
      detail = describeNodeSelection(payload)
    } else if (normalizedTool === 'connectNodes' || normalizedTool === 'disconnectNodes' || normalizedTool === 'canvas.connection.operation') {
      detail = describeConnection(payload)
    } else if (normalizedTool === 'autoLayout' || normalizedTool === 'canvas.layout.apply') {
      detail = describeLayout(payload)
      if (detail) {
        detail = `åº”ç”¨${detail}`
      }
    } else if (normalizedTool === 'runDag') {
      const concurrency = typeof payload.concurrency === 'number' ? payload.concurrency : null
      detail = concurrency ? `å¹¶å‘ ${concurrency}` : 'å…¨å±€æ‰§è¡Œ'
    } else if (normalizedTool === 'formatAll') {
      detail = 'æ•´ç†å½“å‰ç”»å¸ƒ'
    } else if (normalizedTool === 'project.operation') {
      detail = typeof payload.action === 'string' ? payload.action : ''
    } else if (!normalizedTool && payload) {
      detail = describeNodeSelection(payload)
    }
    const text = detail
      ? `${baseLabel}ï¼š${detail}`
      : baseLabel
    return toSingleLine(text) || 'ç”»å¸ƒæ“ä½œ'
  }, [])
  const [input, setInput] = useState('')
  const isLoading = status === 'submitted' || status === 'streaming'

  useEffect(() => {
    if (!isLoading) {
      const allStepsCompleted = planUpdate?.steps?.length
        ? planUpdate.steps.every(step => step.status === 'completed')
        : false
      if (allStepsCompleted || !planUpdate) {
        setIsThinking(false)
      }
    }
  }, [isLoading, planUpdate])

  const reportToolResult = useCallback(async (payload: { toolCallId: string; toolName: string; output?: any; errorText?: string }) => {
    try {
      const token = getAuthToken()
      await fetch(`${apiRoot}/ai/tools/result`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(token ? { Authorization: `Bearer ${token}` } : {}),
        },
        body: JSON.stringify(payload),
      })
    } catch (err) {
      console.warn('[UseChatAssistant] report tool result failed', err)
    }
  }, [apiRoot])

  const runToolHandler = useCallback(async (call: { toolCallId?: string; toolName?: string; input?: any }) => {
    const toolName = call.toolName
    if (!toolName) {
      console.warn('[UseChatAssistant] tool call missing name', call)
      return { errorText: 'æœªæä¾›å·¥å…·åç§°' }
    }
    const handler = (functionHandlers as any)[toolName]
    if (!handler) {
      console.warn('[UseChatAssistant] handler not found', toolName)
      return { errorText: `æœªæ‰¾åˆ°å·¥å…·ï¼š${toolName}` }
    }
    if (AI_DEBUG_LOGS_ENABLED) {
      console.debug('[UseChatAssistant] executing tool', { toolName, toolCallId: call.toolCallId, input: call.input })
    }
    try {
      const result = await handler(call.input || {})
      if (AI_DEBUG_LOGS_ENABLED) {
        console.debug('[UseChatAssistant] tool completed', { toolName, toolCallId: call.toolCallId, result })
      }
      return { output: result }
    } catch (err) {
      console.error('[UseChatAssistant] tool failed', toolName, err)
      return { errorText: err instanceof Error ? err.message : 'å·¥å…·æ‰§è¡Œå¤±è´¥' }
    }
  }, [])

  // è‡ªåŠ¨å°†å¯¹è¯æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    const viewport = scrollAreaViewportRef.current
    if (!viewport) return
    viewport.scrollTo({ top: viewport.scrollHeight, behavior: 'smooth' })
  }, [messages, isThinking])

  const stringifyMessage = (msg: UIMessage) => {
    const describeToolState = (part: any) => {
      const rawToolName = resolveToolName(part)
      const friendlyLabel = buildActionLabel(rawToolName, part.input ?? part.arguments ?? part.params ?? part.data)
      const toolName = friendlyLabel || 'ç”»å¸ƒæ“ä½œ'
      if (part.state === 'output-error') {
        const errorText = typeof part.errorText === 'string' && part.errorText.trim()
          ? `ï¼š${part.errorText.trim()}`
          : ''
        return `âš ï¸ ${toolName} Â· æ‰§è¡Œå¤±è´¥${errorText}`
      }

      if (part.type === 'tool-result' || (part.state === 'output-available' && !part.preliminary)) {
        return `âœ… ${toolName} Â· æ‰§è¡Œå®Œæˆ`
      }

      if (part.state === 'input-streaming' || part.type === 'tool-call') {
        return `ğŸ›  ${toolName} Â· æ­£åœ¨æ•´ç†å‚æ•°`
      }

      if (part.state === 'input-available' || part.type === 'tool-input-available') {
        return `ğŸ›  ${toolName} Â· å‚æ•°å·²å°±ç»ªï¼Œå‡†å¤‡æ‰§è¡Œ`
      }

      if (part.state === 'output-available' && part.preliminary) {
        return `ğŸ›  ${toolName} Â· æ­£åœ¨ç”Ÿæˆç»“æœ`
      }

      return `ğŸ›  ${toolName} Â· æ‰§è¡Œä¸­â€¦`
    }

    const lines: string[] = []
    const toolLineIndex = new Map<string, number>()
    const pushOrUpdateLine = (key: string | undefined, text: string) => {
      if (!text) return
      if (key && toolLineIndex.has(key)) {
        const index = toolLineIndex.get(key)
        if (typeof index === 'number') {
          lines[index] = text
          return
        }
      }
      const index = lines.length
      lines.push(text)
      if (key) {
        toolLineIndex.set(key, index)
      }
    }

    msg.parts.forEach((part: any) => {
      if (part.type === 'text') {
        if (part.text) {
          lines.push(part.text)
        }
        return
      }
      if (part.type === 'reasoning') {
        if (part.text) {
          lines.push(part.text)
        }
        return
      }
      if (part.type === 'data') {
        if (part.data != null) {
          const text = typeof part.data === 'string' ? part.data : JSON.stringify(part.data)
          lines.push(text)
        }
        return
      }
      const isToolPart = part.type === 'tool-result' || isToolCallPart(part)
      if (isToolPart) {
        const summary = describeToolState(part)
        const key = part.toolCallId || part.id || (resolveToolName(part) ? `tool-${resolveToolName(part)}` : undefined)
        const detailLines: string[] = []
        if (isToolCallPart(part)) {
          const args = part.input ?? part.arguments ?? part.params ?? part.data
          const argText = summarizePayload(args)
          if (argText) {
            detailLines.push(`å‚æ•°ï¼š${argText}`)
          }
        }
        if ((part.type === 'tool-result' || part.state === 'output-available') && part.output) {
          const outputText = summarizePayload(part.output)
          if (outputText) {
            detailLines.push(`ç»“æœï¼š${outputText}`)
          }
        }
        const text = detailLines.length ? `${summary}\n${detailLines.join('\n')}` : summary
        pushOrUpdateLine(key, text)
      }
    })

    return lines.filter(Boolean).join('\n')
  }

  const renderRoleLabel = (role?: string) => {
    if (role === 'user') return 'ä½ '
    if (role === 'assistant') return 'Aurora'
    if (role === 'system') return 'ç³»ç»Ÿ'
    return role || 'æ¶ˆæ¯'
  }

  const renderMessageBubble = (msg: UIMessage) => {
    const isUser = msg.role === 'user'
    const bubbleBackground = isUser ? userBubbleBackground : assistantBubbleBackground
    const bubbleBorder = isUser ? userBubbleBorder : assistantBubbleBorder
    return (
      <Stack key={msg.id} align={isUser ? 'flex-end' : 'flex-start'} gap={4} style={{ width: '100%' }}>
        <Text size="xs" c="rgba(255,255,255,0.5)">
          {renderRoleLabel(msg.role)}
        </Text>
        <Box
          style={{
            background: bubbleBackground,
            border: bubbleBorder,
            color: messageTextColor,
            borderRadius: 12,
            padding: '12px 16px',
            maxWidth: '88%',
            alignSelf: isUser ? 'flex-end' : 'flex-start',
            boxShadow: bubbleShadow,
            backdropFilter: 'blur(18px)',
            position: 'relative'
          }}
        >
          <Text size="sm" style={{ whiteSpace: 'pre-wrap', color: 'inherit' }}>
            {stringifyMessage(msg)}
          </Text>
        </Box>
      </Stack>
    )
  }
  const removeImagePromptAttachment = useCallback((attachmentId: string) => {
    setImagePromptAttachments(prev => prev.filter(att => att.id !== attachmentId))
    setActivePromptAttachmentId(prev => (prev === attachmentId ? null : prev))
  }, [])

  const handleImagePromptUpload = useCallback(async (files: FileList | File[]) => {
    if (!isGptModel) {
      toast('ä»… GPT æ¨¡å‹æ”¯æŒå›¾ç‰‡æç¤ºè¯', 'error')
      return
    }
    if (imagePromptAttachments.length >= MAX_IMAGE_PROMPT_ATTACHMENTS) {
      toast(`ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡`, 'error')
      return
    }
    const availableSlots = MAX_IMAGE_PROMPT_ATTACHMENTS - imagePromptAttachments.length
    const normalizedFiles = normalizeFileList(files)
    const sanitizedFiles = normalizedFiles.slice(0, availableSlots)
    if (!sanitizedFiles.length) {
      toast(`ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡`, 'error')
      return
    }
    if (normalizedFiles.length > sanitizedFiles.length) {
      toast(`ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡ï¼Œå¤šä½™çš„å›¾ç‰‡å·²è¢«å¿½ç•¥`, 'info')
    }
    const processFile = async (file: File) => {
      setImagePromptLoadingCount(count => count + 1)
      try {
        const dataUrl = await fileToDataUrl(file)
        const attachmentId = nanoid()
        setImagePromptAttachments(prev => [...prev, { id: attachmentId, preview: dataUrl, prompt: '', ready: false }])
        setActivePromptAttachmentId(null)
        try {
          const task = await runTaskByVendor('openai', {
            kind: 'image_to_prompt',
            prompt: DEFAULT_REVERSE_PROMPT_INSTRUCTION,
            extras: { imageData: dataUrl },
          })
          const nextPrompt = extractTextFromTaskResult(task)
          if (nextPrompt) {
            setImagePromptAttachments(prev => prev.map(att => att.id === attachmentId ? { ...att, prompt: nextPrompt, ready: true } : att))
            toast('å·²æ ¹æ®å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼Œå‘é€æ—¶å°†è‡ªåŠ¨é™„å¸¦', 'success')
          } else {
            removeImagePromptAttachment(attachmentId)
            toast('æ¨¡å‹æœªè¿”å›æç¤ºè¯ï¼Œè¯·ç¨åå†è¯•', 'error')
          }
        } catch (error) {
          removeImagePromptAttachment(attachmentId)
          const message = error instanceof Error ? error.message : 'è§£æå›¾ç‰‡å¤±è´¥'
          toast(message, 'error')
        }
      } catch (error) {
        const message = error instanceof Error ? error.message : 'è§£æå›¾ç‰‡å¤±è´¥'
        toast(message, 'error')
      } finally {
        setImagePromptLoadingCount(count => Math.max(0, count - 1))
      }
    }
    await Promise.all(sanitizedFiles.map(file => processFile(file)))
  }, [imagePromptAttachments.length, isGptModel, removeImagePromptAttachment])

  const handleImagePromptChange = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.currentTarget.files
    if (!files || files.length === 0) return
    const clonedFiles = normalizeFileList(files)
    event.currentTarget.value = ''
    if (clonedFiles.length > 0) {
      void handleImagePromptUpload(clonedFiles)
    }
  }, [handleImagePromptUpload])

  const handleImagePromptButtonClick = useCallback(() => {
    if (!isGptModel) {
      toast('ä»… GPT æ¨¡å‹æ”¯æŒå›¾ç‰‡æç¤ºè¯', 'error')
      return
    }
    if (imagePromptAttachments.length >= MAX_IMAGE_PROMPT_ATTACHMENTS) {
      toast(`ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡`, 'error')
      return
    }
    imagePromptInputRef.current?.click()
  }, [imagePromptAttachments.length, isGptModel])

  const handleToolbarAction = useCallback((feature: string) => {
    toast(`${feature} å³å°†ä¸Šçº¿`, 'info')
  }, [])

  const handleTextareaPaste = useCallback((event: React.ClipboardEvent<HTMLTextAreaElement>) => {
    const clipboardData = event.clipboardData
    if (!clipboardData) return
    const files: File[] = []
    const items = clipboardData.items
    if (items && items.length) {
      for (let i = 0; i < items.length; i += 1) {
        const item = items[i]
        if (item.kind === 'file' && item.type?.startsWith('image/')) {
          const file = item.getAsFile()
          if (file) files.push(file)
        }
      }
    }
    if (!files.length && clipboardData.files && clipboardData.files.length) {
      files.push(
        ...Array.from(clipboardData.files).filter(file => file.type?.startsWith('image/'))
      )
    }
    if (!files.length) return
    if (!isGptModel) {
      toast('ä»… GPT æ¨¡å‹æ”¯æŒå›¾ç‰‡æç¤ºè¯', 'error')
      return
    }
    if (imagePromptAttachments.length >= MAX_IMAGE_PROMPT_ATTACHMENTS) {
      toast(`ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡`, 'error')
      return
    }
    event.preventDefault()
    void handleImagePromptUpload(files)
  }, [handleImagePromptUpload, imagePromptAttachments.length, isGptModel])

  const onSubmit = (e?: any) => {
    if (e?.preventDefault) e.preventDefault()
    const trimmed = input.trim()
    const attachmentPrompts = imagePromptAttachments
      .map((attachment, index) => {
        const prompt = attachment.prompt?.trim()
        if (!prompt) return null
        const label = imagePromptAttachments.length > 1 ? `ã€å›¾ç‰‡æç¤º${index + 1}ã€‘` : 'ã€å›¾ç‰‡æç¤ºã€‘'
        return `${label}${prompt}`
      })
      .filter(Boolean) as string[]
    if (!trimmed && attachmentPrompts.length === 0) return
    const pieces: string[] = []
    if (trimmed) pieces.push(trimmed)
    pieces.push(...attachmentPrompts)
    sendMessage({ text: pieces.join('\n\n') })
    setInput('')
    setImagePromptAttachments([])
    setActivePromptAttachmentId(null)
    setThinkingEvents([])
    setPlanUpdate(null)
    setIsThinking(true)
  }

  useEffect(() => {
    const toolCalls = messages.flatMap(msg =>
      (msg.parts || [])
        .filter((part: any) => isToolCallPart(part))
        .map((part: any) => {
          const parsedInput = parseJsonIfNeeded(part.input ?? part.arguments ?? {})
          const hasPayload = parsedInput && typeof parsedInput === 'object' && Object.keys(parsedInput).length > 0
          const ready = part.state === 'input-available' || part.type === 'tool-input-available' || hasPayload
          const toolCallId = typeof part.toolCallId === 'string' && part.toolCallId.trim() ? part.toolCallId.trim() : undefined
          const toolName = resolveToolName(part)
          if (!ready || !toolCallId || !toolName) return null
          return {
            toolCallId,
            toolName,
            input: parsedInput
          }
        })
        .filter(Boolean)
    )
    if (AI_DEBUG_LOGS_ENABLED && toolCalls.length) {
      console.debug('[UseChatAssistant] detected tool calls', toolCalls)
    }
    toolCalls.forEach(async (call) => {
      if (!call.toolCallId || handledToolCalls.current.has(call.toolCallId)) return
      handledToolCalls.current.add(call.toolCallId)
      const { output, errorText } = await runToolHandler(call)
      if (errorText) {
        await addToolResult({ state: 'output-error', tool: call.toolName as any, toolCallId: call.toolCallId, errorText })
      } else {
        await addToolResult({ state: 'output-available', tool: call.toolName as any, toolCallId: call.toolCallId, output: output as any })
      }
      await reportToolResult({ toolCallId: call.toolCallId, toolName: call.toolName, output, errorText })
    })
  }, [messages, addToolResult, runToolHandler, reportToolResult])

  useEffect(() => {
    const token = getAuthToken()
    if (!token) return
    const unsubscribe = subscribeToolEvents({
      url: `${apiRoot}/ai/tool-events`,
      token,
      onEvent: async (event: ToolEventMessage) => {
        if (event.type === 'tool-call') {
          if (!event.toolCallId || handledToolCalls.current.has(event.toolCallId)) return
          handledToolCalls.current.add(event.toolCallId)
          const toolName = event.toolName
          if (!toolName) {
            console.warn('[UseChatAssistant] tool-call missing name from stream', event)
            await reportToolResult({ toolCallId: event.toolCallId, toolName: 'unknown', errorText: 'æœªæä¾›å·¥å…·åç§°' })
            return
          }
          const normalizedInput = parseJsonIfNeeded(event.input)
          const { output, errorText } = await runToolHandler({ ...event, toolName, input: normalizedInput })
          await reportToolResult({ toolCallId: event.toolCallId, toolName, output, errorText })
          return
        }

        if (event.type === 'tool-result') {
          const thinking = extractThinkingEvent(event)
          if (thinking) {
            setThinkingEvents(prev => [...prev, thinking])
            setIsThinking(true)
            return
          }

          const planPayload = extractPlanUpdate(event)
          if (planPayload) {
            setPlanUpdate(planPayload)
            const done = planPayload.steps.every(step => step.status === 'completed')
            if (done) {
              setIsThinking(false)
            }
          }
        }
      }
    })
    return () => {
      unsubscribe()
    }
  }, [apiRoot, runToolHandler, reportToolResult])

  const injectSystemPrompt = () => {
    setMessages(prev => [
      ...prev,
      {
        id: nanoid(),
        role: 'system',
        parts: [{ type: 'text', text: 'ä½ æ˜¯TapCanvasçš„AIå·¥ä½œæµåŠ©æ‰‹' }]
      }
    ])
  }

  const uploadTooltipLabel = !isGptModel
    ? 'ä»… GPT æ¨¡å‹æ”¯æŒå›¾ç‰‡æç¤ºè¯'
    : imagePromptAttachments.length >= MAX_IMAGE_PROMPT_ATTACHMENTS
      ? `ä¸€æ¬¡æœ€å¤šä¸Šä¼  ${MAX_IMAGE_PROMPT_ATTACHMENTS} å¼ å›¾ç‰‡`
      : 'ä¸Šä¼ æˆ–ç²˜è´´å›¾ç‰‡ç”Ÿæˆæç¤ºè¯'

  const horizontalJustify = position === 'left' ? 'flex-start' : 'flex-end'

  if (!opened) return null

  return (
    <Box
      style={{
        position: 'fixed',
        inset: 0,
        display: 'flex',
        alignItems: 'flex-end',
        justifyContent: horizontalJustify,
        padding: '72px 32px 32px',
        zIndex: 200,
        pointerEvents: 'auto'
      }}
    >
      <Box style={{ width, maxWidth: 'min(460px, calc(100vw - 64px))', pointerEvents: 'auto' }}>
      <Paper
        radius={12}
        shadow="xl"
        style={{
          background: panelBackground,
          border: panelBorder,
          boxShadow: panelShadow,
          overflow: 'hidden',
          backdropFilter: 'blur(18px)',
          display: 'flex',
          flexDirection: 'column',
          minHeight: 560,
          height: 'min(840px, calc(100vh - 140px))'
        }}
      >
        <Box
          px="xl"
          pt="lg"
          pb="sm"
          style={{ borderBottom: headerBorder, background: headerBackground, flexShrink: 0, backdropFilter: 'blur(12px)' }}
        >
          <Group justify="space-between" align="center">
            <Group gap={8} align="center" style={{ color: '#eef2ff' }}>
              <ActionIcon
                size="sm"
                variant="subtle"
                styles={{ root: { background: toolbarIconBackground, border: 'none', color: sparklesColor, boxShadow: '0 8px 18px rgba(3,5,12,0.4)' } }}
              >
                <IconSparkles size={14} />
              </ActionIcon>
              <Select
                size="xs"
                value={model}
                onChange={(value) => value && setModel(value)}
                data={assistantModelOptions.map(option => ({ value: option.value, label: option.label }))}
                aria-label="é€‰æ‹©æ¨¡å‹"
                withinPortal
                styles={{
                  input: {
                    background: 'transparent',
                    border: 'none',
                    color: '#f3f5ff',
                    paddingLeft: 8,
                    paddingRight: 32,
                    height: 32,
                    boxShadow: 'none'
                  },
                  dropdown: {
                    background: 'rgba(5,8,16,0.95)',
                    border: '1px solid rgba(255,255,255,0.08)',
                    backdropFilter: 'blur(14px)'
                  },
                  item: {
                    borderRadius: 16,
                    color: '#eaf0ff'
                  }
                }}
              />
            </Group>
            <Group gap={4} align="center">
              <ActionIcon
                size="sm"
                variant="subtle"
                styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e3e7ff', boxShadow: '0 8px 18px rgba(3,5,12,0.4)' } }}
              >
                <IconWifi size={14} />
              </ActionIcon>
              <ActionIcon
                size="sm"
                variant="subtle"
                styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e3e7ff', boxShadow: '0 8px 18px rgba(3,5,12,0.4)' } }}
              >
                <IconBattery2 size={14} />
              </ActionIcon>
              <ActionIcon
                size="sm"
                variant="subtle"
                styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e3e7ff', boxShadow: '0 8px 18px rgba(3,5,12,0.4)' } }}
              >
                <IconDots size={14} />
              </ActionIcon>
              <Tooltip label="å…³é—­">
                <ActionIcon
                  variant="subtle"
                  onClick={onClose}
                  styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: closeIconColor, boxShadow: '0 8px 18px rgba(3,5,12,0.4)' } }}
                >
                  <IconX size={14} color={closeIconColor} />
                </ActionIcon>
              </Tooltip>
            </Group>
          </Group>
        </Box>

        <Box
          style={{ flex: 1, minHeight: 0, display: 'flex' }}
        > 
          <Box
            sx={{
              flex: 1,
              minHeight: 0,
              background: logBackground,
              borderRadius: 12,
              border: logBorder,
            
            }}
            style={{ 
              flex: 1, 
              minHeight: 0, 
              display: 'flex',  
              position: 'relative',
              overflow: 'hidden',
              boxShadow: '0 28px 60px rgba(3,5,15,0.65)',
              backdropFilter: 'blur(22px)',
              flexDirection: 'column' 
            }}
          >
            <Box style={{ flex: 1, minHeight: 0, position: 'relative', zIndex: 1 }}>
              <ScrollArea style={{ height: '100%' }} type="auto" viewportRef={scrollAreaViewportRef}>
                <Stack gap="md" style={{ padding: 24, paddingBottom: 16 }}>
                  {messages.length === 0 && (
                    <Text size="sm" c="rgba(255,255,255,0.55)" ta="center">
                      å‘ Aurora æ‰“ä¸ªã€Œæ™šä¸Šå¥½ã€çš„æ‹›å‘¼ï¼Œæˆ–æè¿°ä½ æƒ³ç”Ÿæˆçš„åˆ†é•œä¸æ°›å›´ã€‚
                    </Text>
                  )}

                  {messages.map(renderMessageBubble)}

                  {isThinking && (
                    <Group gap={6} align="center">
                      <Loader size="xs" color="gray" />
                      <Text size="xs" c="rgba(255,255,255,0.6)">Aurora æ­£åœ¨æ€è€ƒâ€¦</Text>
                    </Group>
                  )}
                </Stack>
              </ScrollArea>
            </Box>

            <input
              ref={imagePromptInputRef}
              type="file"
              accept="image/*"
              multiple
              style={{ display: 'none' }}
              onChange={handleImagePromptChange}
            />
            <form
              onSubmit={onSubmit}
              style={{ padding: 24, paddingTop: 16, position: 'relative', zIndex: 1, flexShrink: 0 }}
            >
              <Box
                style={{
                  background: inputBackground,
                  borderRadius: 12,
                  boxShadow: '0 25px 60px rgba(2,6,20,0.65)',
                  padding: 12,
                  border: inputBorder
                }}
              >
                <Stack gap="xs">
                  <Box>
                    <Textarea
                      minRows={3}
                      placeholder="å‘å‡ºçµæ„Ÿæˆ–é—®å€™ï¼Œæ”¯æŒç²˜è´´/ä¸Šä¼ å›¾ç‰‡â€¦"
                      value={input}
                      onChange={(e) => setInput(e.currentTarget.value)}
                      onPaste={handleTextareaPaste}
                      disabled={isLoading}
                      onKeyDown={(e) => {
                        if ((e.metaKey || e.ctrlKey) && e.key === 'Enter') {
                          e.preventDefault()
                          onSubmit()
                        }
                      }}
                      styles={{
                        input: {
                          background: 'transparent',
                          borderColor: 'transparent',
                          color: inputColor,
                          paddingRight: 24,
                          paddingBottom: 16,
                          borderRadius: 8,
                          boxShadow: 'none'
                        }
                      }}
                    />
                  </Box>
                  <Group justify="space-between" align="center" mt="sm">
                    <Group gap="xs">
                      <Tooltip label={uploadTooltipLabel}>
                        <ActionIcon
                          variant="subtle"
                          onClick={handleImagePromptButtonClick}
                          disabled={imagePromptLoading || !isGptModel || imagePromptAttachments.length >= MAX_IMAGE_PROMPT_ATTACHMENTS}
                          styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e4edff', borderRadius: 999 } }}
                        >
                          {imagePromptLoading ? <Loader size="xs" /> : <IconPhoto size={16} />}
                        </ActionIcon>
                      </Tooltip>
                      <Tooltip label="è¯­éŸ³è¾“å…¥ Â· å³å°†å¼€æ”¾">
                        <ActionIcon
                          variant="subtle"
                          onClick={() => handleToolbarAction('è¯­éŸ³è¾“å…¥')}
                          styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e4edff', borderRadius: 999 } }}
                        >
                          <IconMicrophone size={16} />
                        </ActionIcon>
                      </Tooltip>
                      <Tooltip label="çµæ„Ÿè¡¨æƒ… Â· å³å°†ä¸Šçº¿">
                        <ActionIcon
                          variant="subtle"
                          onClick={() => handleToolbarAction('çµæ„Ÿè¡¨æƒ…')}
                          styles={{ root: { background: toolbarIconBackground, border: toolbarIconBorder, color: '#e4edff', borderRadius: 999 } }}
                        >
                          <IconMoodSmile size={16} />
                        </ActionIcon>
                      </Tooltip>
                    </Group>
                    <Button
                      type="submit"
                      loading={isLoading}
                      leftSection={<IconSend size={16} />}
                      radius="xl"
                      styles={{
                        root: {
                          background: glowingSendBackground,
                          boxShadow: '0 18px 40px rgba(63,129,255,0.55)',
                          border: 'none',
                          minWidth: 132
                        }
                      }}
                    >
                      å‘é€
                    </Button>
                  </Group>
                  {imagePromptAttachments.length > 0 && (
                    <Stack gap="sm">
                      {imagePromptAttachments.map((attachment, index) => (
                        <Group key={attachment.id} gap="sm" align="center" wrap="nowrap">
                          <Box
                            style={{
                              position: 'relative',
                              width: 90,
                              height: 90,
                              borderRadius: 8,
                              overflow: 'hidden',
                              border: assistantBubbleBorder,
                              background: 'rgba(255,255,255,0.03)',
                              flex: '0 0 auto',
                            }}
                          >
                            <Box
                              component="img"
                              src={attachment.preview}
                              alt={`prompt preview ${index + 1}`}
                              style={{ width: '100%', height: '100%', objectFit: 'cover' }}
                            />
                            <ActionIcon
                              size="xs"
                              variant="filled"
                              color="dark"
                              radius="xl"
                              onClick={() => removeImagePromptAttachment(attachment.id)}
                              style={{ position: 'absolute', top: 4, right: 4, background: 'rgba(0,0,0,0.55)' }}
                            >
                              <IconX size={12} />
                            </ActionIcon>
                          </Box>
                          <Stack gap={4} style={{ flex: 1 }}>
                            <Group gap={6}>
                              <Text size="xs" c="rgba(255,255,255,0.6)">
                                å›¾ç‰‡æç¤ºè¯{imagePromptAttachments.length > 1 ? ` #${index + 1}` : ''}
                              </Text>
                              <Badge size="xs" variant="light" color={attachment.ready ? 'green' : 'gray'}>
                                {attachment.ready ? 'å·²ç”Ÿæˆ' : 'ç”Ÿæˆä¸­'}
                              </Badge>
                            </Group>
                            <ScrollArea.Autosize mah={90} type="hover">
                              <Text size="sm" c={messageTextColor} style={{ whiteSpace: 'pre-wrap' }}>
                                {attachment.prompt || 'æ­£åœ¨ç”Ÿæˆæç¤ºè¯â€¦'}
                              </Text>
                            </ScrollArea.Autosize>
                            <Group gap="xs">
                              <Tooltip label={attachment.ready ? 'æŸ¥çœ‹å›¾ç‰‡ä¸æç¤ºè¯è¯¦æƒ…' : 'æç¤ºè¯ç”Ÿæˆä¸­'}>
                                <ActionIcon
                                  variant="light"
                                  color="violet"
                                  size="sm"
                                  disabled={!attachment.ready}
                                  onClick={() => attachment.ready && setActivePromptAttachmentId(attachment.id)}
                                >
                                  <IconEye size={14} />
                                </ActionIcon>
                              </Tooltip>
                              <Tooltip label="å¤åˆ¶æç¤ºè¯">
                                <CopyButton value={attachment.prompt || ''}>
                                  {({ copy }) => (
                                    <ActionIcon
                                      variant="light"
                                      color="gray"
                                      size="sm"
                                      disabled={!attachment.prompt}
                                      onClick={copy}
                                    >
                                      <IconBulb size={14} />
                                    </ActionIcon>
                                  )}
                                </CopyButton>
                              </Tooltip>
                              <Text size="xs" c="rgba(255,255,255,0.6)">å‘é€æ—¶å°†é™„å¸¦</Text>
                            </Group>
                          </Stack>
                        </Group>
                      ))}
                    </Stack>
                  )}
                </Stack>
              </Box>
            </form>
          </Box>
        </Box>
        <Modal
          opened={!!activePromptAttachment}
          onClose={() => setActivePromptAttachmentId(null)}
          title="å›¾ç‰‡æç¤ºè¯è¯¦æƒ…"
          centered
          size="lg"
        >
          {activePromptAttachment && (
            <Stack>
              <Box
                component="img"
                src={activePromptAttachment.preview}
                alt="attachment preview"
                style={{ width: '100%', borderRadius: 12, objectFit: 'contain', maxHeight: 320 }}
              />
              <Divider my="xs" />
              <Group justify="space-between" align="center">
                <Text size="sm" fw={600}>ç”Ÿæˆçš„æç¤ºè¯</Text>
                <CopyButton value={activePromptAttachment.prompt || ''}>
                  {({ copy }) => (
                    <Button size="xs" variant="light" onClick={copy}>å¤åˆ¶æç¤ºè¯</Button>
                  )}
                </CopyButton>
              </Group>
              <ScrollArea h={180}>
                <Text size="sm" style={{ whiteSpace: 'pre-wrap' }}>{activePromptAttachment.prompt || 'æš‚æ— å†…å®¹'}</Text>
              </ScrollArea>
            </Stack>
          )}
        </Modal>
      </Paper>
    </Box>
  </Box>
  )
}

export default UseChatAssistant
